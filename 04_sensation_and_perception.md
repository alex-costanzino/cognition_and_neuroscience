# Sensation and perception
Stimulation $\to$ Transduction $\to$ Sensation $\to$ Perception.

* **Sensation**: it's the term given to the neural processes that correspond most closely to the concept of detection. It occours throughout the translation of information from the environment into a neural signal, a reprsentation of the physical properties of the environmental info (i.e. brightness, loudness, pitch, texture, etc...);
* **Perception**: refers to the identification of features of what is being sensed and often its recognition;
* **Attention**: how we mentally prioritize the perception of one of a few stimuli within our environment;
* **Action**: isolated acts of motor control, goals or plans that can be abstracted from isolated movements;

## Neural code
The nervous system represents the information - acquired through sensation - about an observed object, with a neural code.
The neural code is a system for representing information in a format that is different from the physical properties, in a way that the nervous system can understand and manipulate.
This code is made up of action potentials and neurotransmitters to convey information about features of the environment.

## Transduction
Usually transduction refers to the conversion of physical energy into the neural code.
* **Vision**: the retina transduces light of different wavelenghts;
* **Audition**: cochlea transduces fluctuations in air pressure;
* **Somatosensation**: receptors in the skin transduce different mechanical forces, chemical agents and temperatures (different receptors, different firing rates).

It would be an oversimplification to think that sensation, perception, attention and action go in this precise order, and to think that neural information processing is a strictly feedforward system. It's also a mistake consider the brain as a passive receiver of information, until a stimulus comes to activate it and kick-start it into an action.

A better model of brain functioning it to think of a brain as constantly representing the world.

## The dominant sense in primates: vision
The **visual field** is the spatial extent of everything that yo can see right now. It doesn't look all the same though, there is a gradient around the fixation point (non-homogeneous point of view). When you pay attention to the sharpness-of-focus of your vision for words, one or two lines above or below of your current reading, your **acuity** falls of quite quickly in all directions.

The center of gaze, where your acuity is sharpest, is referred to as **foveal vision** because it corresponds to the part of your retina called **fovea**.

### How does retina work?
Phototransduction is the process of converting light into neural signal, thanks to specialized cells called photoreceptors. We have cones, mostly in the fovea, and rods, mostly in the periphery.

Photoreceptors contain a pigment called rhodospin, that when impacted by light undergoes conformational changes, that trigger an intracellular molecular cascade, resulting in the closing of membrane-spanning ion channels.
Thus, a type of physical energy (electromagnetic radiation with wavelenght between $400 nm$ and $700 nm$, visible light) is converted into an electrical signal, that change the mebrane potential of the photoreceptor cell.
This change in membrane potential produces currents within the complex cellular circuitry of the retina, leading to APs generated by the retinal ganglion cells, the output neurons of the retina, projecting to the lateral geniculate nucleus (LGN).

Density of photoreceptors in the retina is not uniform, hence the existence i.e. of blind spot, that brain fills automatically.

### Visual hemifields and quadrants
The visual field can be divided into two halves called hemifields (left and right, or upper and lower), or in four quadrants.
The horizontal and vertical meridiand define the different portions of the visual field.
<center>  <img  src=https://i.ibb.co/d4c0kNq/opticchiasm.gif  width="500px"  />  </center>

Some neuropsychological terms and studies:
* Quadrantopia: blindness of a quadrant;
* Hemianopia: blindness of one hemifield;
* Scotoma: smaller lesion within the quadrant.

### Retinotropic organization
Everything in the primary visual cortex (V1) is flipped wrt the visual field. This is due to the optics of the eye: since the shape of the retina is concave, the light refleting objects below the point of fixation will be projected into the upper retina and viceversa.
The same organization will be maintened with the projections to the thalamus.

At the optic chiasm nasal portions of the projections will cross to the controlateral hemisphere, while temporal projections will project ipsilaterally.

The layout of the retina is maintained across the projections: adjacent part of the retina are projected into adjacent portions of the LGN, that will project to adjacent portions of V1. Hence: 
* The spatial organization of V1 reflects the spatial organization of the retina;
* The functional topography of V1 mirrors the functional topography of the retina.

Optic nerves convey eye-specific information, optic tracts convey visual field specific information.

### Cortical magnification
Representation in the fovea is higher than in the rest of the visual field.
<center>  <img  src=https://i.ibb.co/6FdLPmX/fvavv.png  width="400px"  />  </center>

V1 will be sensitive to stimulation within a larger or smaller portion of the visual field, depending on what portion of the retina a neuron represents.
This fundamental property of a sensory neuron is reffered to as its **receptive field**. In V1
* Receptive fields at regions receving input from the fovea are smallest. There are more neurons, so each one can focus on a smaller portion (higher spatial resolution of the fovea);
* Receptive fields at regions receving input from the periphery are largest, they cover very large spaces (lower spatial resolution of the periphery);

It's known that $\text{Visual angle} \approx \frac{\text{Object size}}{\text{Distance}}$.

### How does the brain accomplish visual perception?
Information processing happens in the primary visual cortex.
In 1958, **David Hubel** and **Torsten Wiesel** got a Nobel Prize for the discovery of the functioning of the primary visual cortex in the cat.
They projected small spots of light into the eye of a cat while recording from V1 neurons. The breakthrough discover came by accident, while changing the slides in the ophthalmoscope: a neuron responded with bursts of APs, each time the shadow of an edge of the glass slide passed across the retina at a particular angle (different responses to differe orientation).
Research moved to tiny spots to bars of light, defining the now called **orientation selectivity** of neurons on V1 (pooling across simpler inputs in the LGN, it's the principle that inspired the SIFT descriptors).
<center>  <img  src=https://i.ibb.co/R0gdrth/photo-2021-05-01-15-47-27.jpg  width="700px"  />  </center>

The orientation tuning is a specific example of a broader phenomenon that arises in V1: the construction of information from more elemental information.
There are at least six transforms of elemental information in visual features. Among them:
* Orientation selectivity;
* Direction selectivity;
* Higher acuity;
* Binocular disparity;
* Convergence of center-surround cells (perception of contours);
* Construction of color from three cone types.

**Direction selectivity**: i.e. moving objects. Neuron $n_1$ and adjacent neuron $n_2$ in LGN respond to visual stimulation at the time $t_1$ and $t_2$. Pooling of receptive field in V1 will give rise to a V1 neuron coding for this time lag between the two cells in LGN. The information built in V1 is that there is an object in a given part of the visual field moving in a particular direction.

The construction of information from more elemental information can be considered as low level properties whose combination give rise to complex objects we recognize and interact with. 
An influential way of understanding information processing in V1 is to view these neurons as **feature detectors**.
I.e. a face is a recurrent stimulus. At a low level I don't see immediately the face, I need to reconstruct it, and there's a part of the brain specialized in this.

**Hypercolumns and pinwheels**: primary visual cortex is organized in hypercolumns, a grid of orientation columns that together represent every orientation that could fall within a receptive field. There hypercolumns are tuned to all visual features.
Hypercolumns are organized in pinwheels, with the center being insensitive to orientation.

### Feedforward and feedback projections of V1
For each feedforward axon (from LGN to V1), we have from three to nine feedback axons (from V1 to LGN).

For sensory input, to be rapidly assessed and to guide the behaviour of an organism, it needs to be continualy placed in the context of hypotheses formulated by higher brain centers. Feedback is a way to correct these hypotheses.

**Why our visual system requires such a disproportionate balance between feedforward and feedback projections?** Anticipatory wave activity back to LGN requires a lot of neural circuitry, indeed organisms use their sensory input to formulate new hypotheses in higher brain centres which must be brought back to the core.
Moreover, LGN is part of the thalamus, connected to the *thalamic reticular nucleus* (TRN), that is made exclusively of GABAergic inhibitory neurons, whose outputs is focused on the thalamus, suited to implement an inhibitory surround.

## The relation between visual processing and the brain's psychological state
It was traditionally assumed that synchronous neural activiry generating the alpha rhythm ($8-12 Hz$) is associated with areas of the cortex that are not processing information (i.e. at rest or idling). When eyes are open the visual system would get the message to do something, getting out of an idling mode.

An alternative account is that the brain may configure itself in different states to optimize the performance on the currently prioritized task, by selectively inhibiting irrelevant items (i.e. visual perception is usually prioritized when eyes are open).

### Spontaneous fluctuations in posterior alpha-band EEG activity reflect variability in excitability of human visual areas (paper)
**Research question**: do alpha oscillations reflect passive idling states or mental (receptive) states? Pre-stimulus oscillations are related to future perception?

**Objective of the design**
1. **Study the mechanisms of how we perceive the world around us**: state-dependency of the visual processing. Wheter a visual event is consciously perceived depends on external factors (i.e. salience), but also on the internal state of the visual network at the time of the visual input (in a certain state some neurons are more likely to fire);
2. **Exploiting the capacity of occipital TMS to create visual experience (phosphenes)**: bypass of visual pathways, from retina to visual cortex and allows to focus more directly on V1 physiology;
3. EEG recordings online to TMS.

**Methods**
* **Participants and paradigm**: fifteen healty volounteers screened whether seeing TMS-induced phosphenes, nine blind-folded participants reliably perceived phosphenes. From three to five training session at separate days to establish stable percept;
* **Experimental session**: TMS intensity kept constant within subjects after individual titration to evoke phosphenes in $50\%$ of all trials;
* **Protocol**: induction of phosphene by single pulse TMS over occipital pole, with TMS parameters (site, intensity) identical across all trials and continuous EEG recordings online to TMS.
* **Pre-TMS analysis**: EEG analysis prior to TMS pulse delivery to inspect the state-dependency of visual perception;
* **Measure**: oscillatory activity in theta, alpha, beta and gamma frequency bands, calculated using *temporal spectral evolution* (TES) algorithm.

**Result**: the perception of a phosphene depends on the prior state of the visual perception area. A lower intensity in the alpha-band led to the perception of the phosphene, while a higher intensity led to no perception.

**Post-hoc analysis**: the trial-to-trial variability in phosphene perception cannot by explained by:
* **Expectancy**: pre-stimulus $\alpha$ is independent of interstimulus-interval for P-yes/no trials;
* **Overt attention**: eye movements before TMS pulses were not related to $\alpha$-modulation;
* **Drowsiness**: intensity and site simulation were held constant across trials (confirmed by the random, binomial distribution of responses).

### Resting EEG alpha-power over posterior sites indexes baseline visual cortex excitability (paper)
Results of previous experiment report that alpha oscillations represent a momentary index of cortical excitability which fluctuates spontaneously from trial to trial within the same individual.
Correlation between individual alpha power (but not other frequency bands) and cortical excitability (phosphene threshold) confirm a functional role of alpha activity.

Results provide further support to the alpha excitability hypothesis and for an inverse relationship between oscillatory alpha band activity and cortical excitability: alpha activity is not a passive idling state, but instead reflects the momentary state of cortical excitability within and between individuals.

The potential of alpha waves sets a **threshold of perception**: whenever the fluctuation reaches a low point neurons fire even when receiving a sufficiently powerless stimulus that, in case of high potential, is not powerful enough to activate the action potential of the neurons in the area and, therefore, the stimulus gets bypassed (inhibition).
